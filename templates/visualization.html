<!DOCTYPE html>
<html lang="en">
<head>
  <title>What's That Dog?</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <style>
    .navbar{
        margin-bottom: 0px;
        position: fixed;
        width: 100%;
    }
    body {
      font: 20px Montserrat, sans-serif;
      line-height: 1.8;
      color: #f5f6f7;
    }
    p, ul, ol{
      color: black;
      {#text-align: center;#}
    }
    #bodydiv {
        font-size: 14px;
        padding-left: 100px;
        padding-right: 100px;
    }

    footer {
      {#position: fixed;#}
      right: 0;
      left: 0;
      bottom: 0;
      margin-top: 50px;
      padding-top: 20px;
      padding-bottom: 20px;
      background-color: #f8f8f8;;
      color: grey;
      text-align: center;
    }
    /* unvisited link */
    a:link {
        color: #43967F;
    }
    /* visited link */
    a:visited {
        color: #277E66;
    }
    /* mouse over link */
    a:hover {
        color: #5BC6A9;
    }

    h1{
      margin-top: 100px;
    }

    iframe{
      width: 80%;
      display: block;
      margin: auto;
      margin-bottom: 100px;
      margin-top: 100px;
    }

    img{
      display: block;
      margin: auto;
    }

    .tableauPlaceholder{
      width: 80%;
      display: block;
      margin-bottom: 100px;
    }
    .scroll {
        content: url("../static/scroll.png");
    }

    .scroll:hover {
        cursor: pointer;
    }

  </style>
    <script>
    $(document).ready(function() {
        var scrollBottom = $('#bodydiv').offset().top - ($('.navbar').height() + 15);
        $(".scroll").on('click', function() {
            $('html, body').animate({scrollTop: scrollBottom}, 1000, 'swing');
        });
    });
    </script>
</head>
<body>

  <!-- Navbar -->
  <nav class="navbar navbar-default">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="{{ url_for('home') }}">HOME</a>
      </div>
      <div class="collapse navbar-collapse" id="myNavbar">
        <ul class="nav navbar-nav navbar-right">
          <li><a href="{{ url_for('introduction') }}">INTRODUCTION</a></li>
          <li><a href="{{ url_for('visualization') }}">ANALYSIS AND VISUALIZATION</a></li>
{#          <li><a href="{{ url_for('prediction') }}">APPLICATION</a></li>#}
        </ul>
      </div>
    </div>
  </nav>

  <div class="jumbotron text-center" style="background-color:rgb(23, 167, 250); height: 650px;">
    <h1 style="color: white; font-size: 100px;"><img style = "display: inline; width: 10%; height: 10%; margin-right: 35px;" src="https://image.ibb.co/ixbMjf/kisspng-dog-breed-pet-sitting-computer-icons-dogs-vector-5ad7c735912387-3076663115240906775945.png" alt="logo">Analysis & Visualization</h1>
    <h3 style="color: white;">Dog Breed Classification Project</h3>
      <br><br>
      <a class="scroll"></a>
  </div>

  <div id="bodydiv">
      <h3 style="color: black;">Feature Extraction Methods</h3>

      <p>Before exploring the machine learning models, we first decided on various feature extractors used to train these models. The feature extractors we used are:
          <ol>
          <li>Image pixels</li>
          <li>VGG16 features</li>
          <li>ResNet50 features</li>
          <li>Histogram of Oriented Gradients</li>
      </ol></p>

      <p><strong>Pixels</strong></p>
      <p>We started with image pixels because they are the simplest features to extract and many models are able to extract all of the information from these pixels alone. This feature set is more suitable for complex models.</p>

      <p><strong>VGG16 features</strong></p>
      <p>The VGG16 is a pre-trained neural network that was used for image classification of over 1000 different classes. We stripped off the classification part (last few layers) and utilized the output as our feature vector. This vector consisted of 7x7x512 output layer which was converted into a feature vector. We expected this pre-trained model to perform better because it knows what features are important in an image for different object classification. It does however contain many features that are not dog related because of its initial classification task.</p>
      <img src="../static/vgg16Pic.PNG" width="45%"/>

      <p><strong>ResNet50 features</strong></p>
      <p>ResNet50 was similarly a pre-trained neural network but it consisted of a very different architecture to achieve similar performance on the ImageNet object classification task. This model is deeper but with fewer fully connected layers resulting in an overall smaller model with faster test image processing.</p>

      <p><strong>Histogram of Oriented Gradients</strong></p>
      <p>Histogram of gradients is a feature extractor that utilizes the gradients of a grayscale image to form a feature vector. These gradients are calculated by first finding all of the gradient directions at each pixel. These gradients are then combined within a sliding window of 4, 8x8 pixel regions. Inside these regions, the histogram of the gradient directions, magnitudes is calculated and forms the feature vector. This encodes shape information and is robust to image noise.</p>
      <img src="../static/HOGPic.PNG" width="65%"/>

      <h3 style="color: black;">Models</h3>
      <p>Using each of these feature vectors, we passed them through the following series of classifiers.</p>
      <ol>
          <li>K-Nearest-Neighbor</li>
          <li>Decision Trees</li>
          <li>AdaBoost</li>
          <li>Stochastic Gradient Descent</li>
          <li>Support Vector Machine</li>
          <li>Convolutional Neural Network (from scratch)</li>
          <li>Boosted Convolutional Neural Network</li>
      </ol>

      <p><strong>K-Nearest-Neighbor</strong></p>
      <p>We started with this basic classifier to see if our dataset was easily clustered into the different breeds. As expected however, this model performed very poorly. This was because each feature vector contained many background features which was true for all feature extractors. Many images contained people in the foreground or background, and some images included multiple dogs of the same breed. This made this simple classifier perform about the same as randomly guessing.</p>

      <p><strong>Decision Trees</strong></p>
      <p>The next model was the slightly more complex decision tree model. This was tried with the various feature extractors and with varying depths. This approach seemed promising initially with a decision tree of depth 120 reaching a test accuracy of around 13%. Adding additional depths did not increase the results beyond this 13%. </p>
      <img src="../static/decision-tree.PNG" width="55%">

      <p><strong>Adaptive Boosting</strong></p>
      <p>With the promising results from the decision trees we tried using Adaboost on decision tree stubs to augment their results. We used a variety of depths ranging from 1 to 100 but our best results were on depth 10 decision trees with an accuracy near 10%. This however was not significantly better than the single decision tree model. This leads us to believe that the decision trees that are formed are not very diverse and are all extracting the same features. Additionally due to computational complexity we were not able to extend beyond 1200 classifiers of depth 2. Less classifiers were used for deeper decision trees due to the training time. </p>
      <img src="../static/adaboost.PNG" width="52%">

      <p><strong>Stochastic Gradient Descent (SGD)</strong></p>
      <p>After the failed results with the simpler classifiers we tried to use stochastic gradient descent to learn the separation between all of the breeds. The SGD was able to successfully classify many of the breeds using both the VGG16 features and the HOG features. Surprisingly, the HOG features performed better in this case reaching an accuracy of 77%. We believe this is because the VGG16 feature extractor was trained so all dogs were output as a single class while the rest of the features were used to identify the other 999 classes. This lost many of the complex features required to correctly identify similar dog breeds. This led us to believe that the HOG features may be the best for our classification problem.</p>
      <img src="../static/SGD.png" width="60%"/>


      <p><strong>Support Vector Machine</strong></p>
      <p>The support vector machine we built was based on Sci-kit learn SVC platform. In order to achieve multi-class classification, we utilized one-versus-rest method thus the SVM will contains 120 different hyperplane classification boundaries to identify the dog breed. We initialized the SVM using both VGG16 descriptor and the HOG descriptor. Unknowing the linearity of either descriptors, we could not determine if the data can be linearly classified or higher degree classification is need. Thus, a grid search with cross validation was implemented in order to find the optimal hyperparameters. These different parameters are:</p>
      <ul>
          <li>Different feature descriptor of VGG16 and HOG</li>
          <li>Different choice of kernels including linear, polynomial and RBF.</li>
          <li>Different choice of kernels including linear, polynomial and RBF.</li>
          <li>Different values of penalty parameter C to regularize boundary simplicity. </li>
          <li>Different values of  kernel coefficient gamma to regularize how much influence a single training instance has over the other instances.</li>
          <li>Different degrees of polynomial kernels to specify how much generality the boundaries can be.</li>
          <li>Different regularization weights to stop overfitting. </li>
      </ul>
      <p>By exhaustively searching all parameters, the best parameters calculated by validation is using HOG descriptor, RBF kernel, C of 1.0 and gamma of 0.001. The final test score of SVM was 90% accuracy. This confirmed our initial results from the SGD that HOG features were more informative than the VGG16 features without additional tuning.</p>
      <img src="../static/SVMPic.PNG" width="45%"/>
      <img src="../static/SVM.png" width="60%"/>


      <p><strong>Convolutional Neural Network</strong></p>
      <p>Both Convolutional Neural Networks used data augmentation to artificially enlarge the dataset with image translations, rotations, and scale adjustments. </p>

      <p>The CNN we built from scratch consisted of 2 dimensional convolutions where we adjusted the filter size, using the rectified linear unit for activation. After ‘processing’ the images with convolutions, they were placed through a global average pooling layer to flatten the data into one dimension using an average of the detected features. Finally, we fed the resulting parameters through fully connected layers with relu activation once again. These included a dropout rate which randomly selected nodes to ignore every iteration to prevent overfitting. The output layer was 120 nodes, each one representing a category, with softmax activation. We modified the hidden layers, hidden units, epochs, steps per epoch until the optimal model emerged. The optimal model consisted of five convolutional layers with an increasing filter size, followed by two layers of 512 fully connected nodes with 50% dropout rate each. Due to the small amount of data, this model only reached 30% accuracy compared to the others which were all much less.</p>
      <img src="../static/cnn.PNG" width="45%">

      <p>We also created a CNN boosted with the Inception V3 pre-trained network. This network already recognizes some breeds of dogs, so our goal was to enhance the performance by removing the top layers and adding fully connected layers with the correct number of outputs. One fully connected layer of 512 nodes with 50% dropout and a final softmax layer of 120 fully connected nodes resulted in the best performance; however, the overall results with the pre-trained model were not improving. The model reached about 70% test accuracy consistently, which was much higher than the results yielded by CNN from scratch, but appeared to be slightly overfitting the data as the training loss decreased despite the test loss not decreasing. It may have helped to fine-tune individual layers of the Inception V3 model, but unfortunately due to the large size and long training time of the CNN model, this was not accomplished during the project.</p>
      <img src="../static/InceptionPlt.PNG" width="45%"/>

      <p><strong>Final Results</strong></p>
      <p>The summarized results from each of the algorithms and feature extractors are summarized below.</p>
        <style type="text/css">
        .tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc; color:black;}
        .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
        .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
        .tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
        .tg .tg-fymr{font-weight:bold;border-color:inherit;text-align:left;vertical-align:top}
        .tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}
        .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
        </style>
        <table class="tg">
          <tr>
            <th class="tg-fymr">Feature Extractor</th>
            <th class="tg-7btt">Decision Tree</th>
            <th class="tg-7btt">Adaboost</th>
            <th class="tg-7btt">K-Means</th>
            <th class="tg-7btt">SGD</th>
            <th class="tg-7btt">SVM</th>
            <th class="tg-7btt">Neural Network</th>
            <th class="tg-7btt">Boosted CNN</th>
          </tr>
          <tr>
            <td class="tg-0pky">Histogram of Gradients</td>
            <td class="tg-c3ow">1%</td>
            <td class="tg-c3ow">2%</td>
            <td class="tg-c3ow">N/A</td>
            <td class="tg-c3ow">77%</td>
            <td class="tg-c3ow">90%</td>
            <td class="tg-c3ow">N/A</td>
            <td class="tg-c3ow">N/A</td>
          </tr>
          <tr>
            <td class="tg-0pky">VGG16</td>
            <td class="tg-c3ow">13%</td>
            <td class="tg-c3ow">13%</td>
            <td class="tg-c3ow">3%</td>
            <td class="tg-c3ow">54%</td>
            <td class="tg-c3ow">61%</td>
            <td class="tg-c3ow">3%</td>
            <td class="tg-c3ow">N/A</td>
          </tr>
          <tr>
            <td class="tg-0pky">Raw Image</td>
            <td class="tg-c3ow">1.50%</td>
            <td class="tg-c3ow">3%</td>
            <td class="tg-c3ow">N/A</td>
            <td class="tg-c3ow">10%</td>
            <td class="tg-c3ow">12%</td>
            <td class="tg-c3ow">39%</td>
            <td class="tg-c3ow">70%</td>
          </tr>
        </table>
        <br>
      <p><strong>Conclusions</strong></p>
      <p>Through comparison of many different machine learning models, we learned more about what model is suitable for which classification task. For our dataset, the simple models provided insights on what features were useful but did not perform well for the task of classification. Because our dataset was very small in comparison to the number of breeds, many of the traditional methods did not perform as well as expected. Our CNN’s did not have enough training data to determine optimal weights without overfitting to the given examples and thus were not able to perform as well as the support vector approach. Additionally we learned that using pre-trained neural nets to create features is a promising approach for small datasets, but it is important to understand what features the model is generating. With additional tuning of the existing feature extractor we expect that we would be able to get CNN to perform better than the HOG + SVM approach. However for the relatively few parameters that needed tuning, the HOG + SVM approach was very successful without as much experimentation. </p>
    </div>

<!-- Footer -->
<footer class="container-fluid bg-4 text-center">
  <span>Designed by: Khuyen Cao, Trang Ha, Lanhan Mao, Steven Viola, Daniel Wivagg </span>
  <div class="footer-copyright py-3 text-center">
      © 2018 Copyright:
      <a href="https://github.com/ML-Fall18-DogBreed/"> Github </a>
  </div>
</footer>
</body>

</html>
